# MicroService

## Description
Ce projet Spring Boot, "Exam2025", est une application de gestion d'√©tudiants utilisant Spring Data JPA et H2 pour les tests. Il permet de g√©rer les √©tudiants (cr√©ation, mise √† jour, suppression, r√©cup√©ration) via des DTO mapp√©s avec MapStruct. Des exceptions personnalis√©es g√®rent les erreurs, et la documentation de l'API est g√©n√©r√©e avec Swagger. Des tests unitaires sont r√©alis√©s avec Mockito pour assurer la fiabilit√© du code, d√©montrant une approche moderne et robuste pour une application d'entreprise.

---

## Technologies utilis√©es

- **Base H2**
- **Spring Boot 3.4.2**
- **Spring Data JPA**
- **Spring Web**
- **Lombok**
- **Mapstruct**
- **Mockito**
- **OpenApi**

---

## Concepts Impl√©ment√©s

- **CRUD Student**
- **Mapper, DTO**
- **Gestion des Exception [ NotFound, AlreadyExist ]**
- **Test Unitaire Junit**
- **Swagger**

###  Couverture des Teste
![test_list](data/test_list.png)

![test_coverage](data/test_coverage.png)

---

##  Installation et ex√©cution

###  Configuration de la base de donn√©es
Nous avons utilis√© une base de donn√©e embarqu√©e H2 de type fichier
> data/exam2025.mv.db

## üõ†Ô∏è Open Api

L'application expose une API REST permettant de g√©rer une entit√© (ex. : `Contact`).
> **[ Acceder a swagger](http://localhost:8080/swagger-ui/index.html)**

### StudentEntity
```json
{
  "firstName": "Alph",
  "lastName": "Sy",
  "emailPro": "sy@malick",
  "emailPerso": "alpha@sy",
  "phoneNumber": "98659876",
  "address": "Hamo",
  "archive": true,
  "registrationNu": "LKJHJG7668"
}
```
---

# Elastic Stack Docker Compose Setup

Ce projet configure un environnement Elastic Stack avec tous les outils n√©cessaires pour collecter, analyser et visualiser des donn√©es de logs et des m√©triques syst√®me. Utilisez Kibana pour g√©rer et visualiser vos donn√©es Elasticsearch.


## Description des Services

Le fichier `docker-compose.yml` contient plusieurs services pour mettre en place l'Elastic Stack.

### 1. **Elasticsearch** (`es01`)

Ce service est le c≈ìur du stack Elastic. Il g√®re les donn√©es et les index de recherche.

- **Ports expos√©s** : 9200
- **Configuration** : Elasticsearch est configur√© en mode "single-node".
- **Volume** : Les donn√©es sont stock√©es dans un volume persistant `esdata01`.

### 2. **Kibana**

Kibana est l'interface graphique pour interagir avec Elasticsearch. Elle permet de visualiser les donn√©es et logs.

- **Ports expos√©s** : 5601
- **Configuration** : Connect√© √† Elasticsearch via `es01`.
- **Volume** : Les donn√©es de Kibana sont stock√©es dans un volume persistant `kibanadata`.

### 3. **Logstash**

Logstash est utilis√© pour ing√©rer, transformer et envoyer des logs vers Elasticsearch.

- **Configuration** : Utilise un fichier de configuration `logstash.conf` pour d√©finir les pipelines de traitement.
- **Volume** : Les donn√©es de Logstash sont stock√©es dans un volume persistant `logstashdata01`.

### 4. **Filebeat**

Filebeat est utilis√© pour envoyer les logs des fichiers vers Logstash.

- **Volume** : Mont√© avec le r√©pertoire local contenant la configuration de Filebeat et les donn√©es de logs.

### 5. **Metricbeat**

Metricbeat collecte des m√©triques de performance du syst√®me et des containers Docker et les envoie vers Elasticsearch.

## D√©marrage du Projet

Pour d√©marrer l'environnement Elastic Stack, suivez ces √©tapes :

1. Clonez ce d√©p√¥t (ou t√©l√©chargez les fichiers n√©cessaires).
2. Cr√©ez un fichier `.env` et d√©finissez les variables d'environnement requises (voir ci-dessus).
3. Lancer les services avec Docker Compose :

```bash
docker-compose up -d
```

Cela va t√©l√©charger les images Docker n√©cessaires et d√©marrer les services en arri√®re-plan.

### V√©rification de l'√©tat des services

Vous pouvez v√©rifier l'√©tat des services via Docker Compose :

```bash
docker-compose ps
```

### Acc√®s √† Kibana

Une fois les services d√©marr√©s, vous pouvez acc√©der √† Kibana √† l'adresse suivante :

[http://localhost:5601](http://localhost:5601)

Utilisez les identifiants suivants pour vous connecter :

- **Nom d'utilisateur** : `kibana_system`
- **Mot de passe** : D√©finie dans `.env` sous `KIBANA_PASSWORD`

### Acc√®s √† Elasticsearch

Elasticsearch sera accessible via HTTP √† l'adresse suivante :

[http://localhost:9200](http://localhost:9200)

Les logs seront envoy√©s √† Elasticsearch, et vous pourrez les visualiser via Kibana.